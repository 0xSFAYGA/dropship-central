# Dropship Central - Complete Project Context & Architecture Bible

**Read this file completely before generating ANY code. This is your project's DNA.**

---

## üìç PROJECT IDENTITY

**Name:** Dropship Central
**Type:** Multi-Marketplace Dropshipping Automation SaaS
**Status:** MVP Development (Started: Nov 12, 2025)
**Target:** Production-ready backend in 10 days
**Tech Era:** 2025 Best Practices

---

## üéØ PROJECT GOALS

### Primary Goal
Build a **production-grade, extensible backend** for dropshipping automation that:
1. ‚úÖ Scrapes multiple suppliers (Amazon, AliExpress, etc)
2. ‚úÖ Tracks price & stock in real-time
3. ‚úÖ Uploads listings to multiple marketplaces (eBay, Shopify, etc)
4. ‚úÖ Applies business policies automatically (low-stock alerts, margin checks)
5. ‚úÖ Calculates analytics (revenue, profit, trends)
6. ‚úÖ Scales horizontally with async workers

### Secondary Goals
- ‚úÖ Clean, maintainable code
- ‚úÖ Comprehensive testing (80%+ coverage)
- ‚úÖ Easy to extend (plugin systems)
- ‚úÖ Production deployment ready
- ‚úÖ Type-safe (full type hints)
- ‚úÖ Observable (structured logging, metrics)

---

## üèóÔ∏è COMPLETE SYSTEM ARCHITECTURE

### System Components (Big Picture)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FastAPI Application                      ‚îÇ
‚îÇ  (main.py) - HTTP Requests, Routes, Error Handling          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                             ‚îÇ
        Dependency Injection            Middleware
               ‚îÇ                             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
        ‚îÇ             ‚îÇ                    ‚îÇ
        ‚ñº             ‚ñº                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇDatabase‚îÇ   ‚îÇ Redis  ‚îÇ         ‚îÇ Logging  ‚îÇ
    ‚îÇ  (DB)  ‚îÇ   ‚îÇ(Queue) ‚îÇ         ‚îÇ Metrics  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ             ‚îÇ
        ‚îÇ    Job Queue (Redis Streams)
        ‚îÇ    ‚îú‚îÄ scraper:amazon
        ‚îÇ    ‚îú‚îÄ tracker:all
        ‚îÇ    ‚îî‚îÄ syncer:ebay
        ‚îÇ
        ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Worker Processes            ‚îÇ
    ‚îÇ  (Background, Async)         ‚îÇ
    ‚îÇ                              ‚îÇ
    ‚îÇ  ‚îú‚îÄ scraper_worker          ‚îÇ
    ‚îÇ  ‚îú‚îÄ tracker_worker          ‚îÇ
    ‚îÇ  ‚îî‚îÄ syncer_worker           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ             ‚îÇ
         ‚ñº             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇScrapers ‚îÇ   ‚îÇMarketplaces
    ‚îÇ(Plugin) ‚îÇ   ‚îÇ(Plugin)
    ‚îÇ         ‚îÇ   ‚îÇ
    ‚îÇAmazon   ‚îÇ   ‚îÇeBay
    ‚îÇAlixprs  ‚îÇ   ‚îÇShopify
    ‚îÇMore...  ‚îÇ   ‚îÇMore...
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow: Complete Example

```
USER ACTION: "Scrape Amazon product ASIN B123456"

‚îå‚îÄ STEP 1: API Request ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ POST /products/import?asin=B123456                         ‚îÇ
‚îÇ Header: Authorization: Bearer {jwt_token}                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ 1. Route handler validates
                         ‚îÇ 2. Auth check (get_current_user)
                         ‚îÇ 3. ASIN format validation
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 2: Database Transaction                              ‚îÇ
‚îÇ - BEGIN TRANSACTION                                        ‚îÇ
‚îÇ - INSERT jobs (status=PENDING, params={asin})            ‚îÇ
‚îÇ - Get job_id = 789                                        ‚îÇ
‚îÇ - COMMIT                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ INSTANT RESPONSE to user!
                         ‚îÇ {"job_id": "789", "status": "queued"}
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 3: Queue Job (Redis Streams)                        ‚îÇ
‚îÇ await redis.xadd(                                         ‚îÇ
‚îÇ   "scraper:amazon",                                       ‚îÇ
‚îÇ   {                                                       ‚îÇ
‚îÇ     "job_id": "789",                                      ‚îÇ
‚îÇ     "asin": "B123456",                                    ‚îÇ
‚îÇ     "priority": 1,                                        ‚îÇ
‚îÇ     "retry_count": 0                                      ‚îÇ
‚îÇ   }                                                       ‚îÇ
‚îÇ )                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                                   ‚îÇ
          ‚ñº (IN BACKGROUND, SEPARATE PROCESS)‚ñº
‚îå‚îÄ STEP 4: Worker Polling ‚îÄ‚îÄ‚îê    ‚îå‚îÄ STEP 5: Worker Polling ‚îÄ‚îÄ‚îê
‚îÇ scraper_worker #1 polls    ‚îÇ    ‚îÇ scraper_worker #2 polls    ‚îÇ
‚îÇ xreadgroup("scrapers",     ‚îÇ    ‚îÇ xreadgroup("scrapers",     ‚îÇ
‚îÇ   "group-1",               ‚îÇ    ‚îÇ   "group-2",               ‚îÇ
‚îÇ   "scraper:amazon")        ‚îÇ    ‚îÇ   "scraper:amazon")        ‚îÇ
‚îÇ                            ‚îÇ    ‚îÇ                            ‚îÇ
‚îÇ Detects job! ‚úÖ            ‚îÇ    ‚îÇ Sleeps (no jobs)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 6: Execute Scraper                                   ‚îÇ
‚îÇ scraper = registry.get_scraper("amazon")                 ‚îÇ
‚îÇ product = await scraper.get_product("B123456")           ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ INSIDE Scraper.get_product():                            ‚îÇ
‚îÇ   1. Load anti-detection config                          ‚îÇ
‚îÇ   2. Select random proxy from proxy_pool (health_score>70)
‚îÇ   3. Create curl-cffi request with:                      ‚îÇ
‚îÇ      - impersonate="chrome120"                           ‚îÇ
‚îÇ      - Random User-Agent (desktop/mobile)                ‚îÇ
‚îÇ      - Proxy rotation (change every 5 requests)          ‚îÇ
‚îÇ   4. Make request to Amazon                              ‚îÇ
‚îÇ   5. Parse HTML with CSS selectors:                      ‚îÇ
‚îÇ      - title: "Sony WH-1000XM5 Wireless Headphones"    ‚îÇ
‚îÇ      - price: "$348.99"                                  ‚îÇ
‚îÇ      - stock: "In Stock"                                 ‚îÇ
‚îÇ      - rating: "4.8 out of 5"                            ‚îÇ
‚îÇ      - reviews: "2,345"                                  ‚îÇ
‚îÇ      - images: ["img1.jpg", "img2.jpg", ...]           ‚îÇ
‚îÇ   6. Return Product object                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 7: Save to Database                                 ‚îÇ
‚îÇ async with db.begin():                                   ‚îÇ
‚îÇ   # INSERT or UPDATE Product                            ‚îÇ
‚îÇ   stmt = insert(Product).values(                        ‚îÇ
‚îÇ     asin="B123456",                                      ‚îÇ
‚îÇ     supplier="amazon",                                   ‚îÇ
‚îÇ     title="Sony WH-1000XM5...",                         ‚îÇ
‚îÇ     price=348.99,                                        ‚îÇ
‚îÇ     stock="In Stock",                                    ‚îÇ
‚îÇ     ...                                                  ‚îÇ
‚îÇ   ).on_conflict_do_update(...)                          ‚îÇ
‚îÇ   result = await db.execute(stmt)                       ‚îÇ
‚îÇ   product_id = result.inserted_primary_key[0]           ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ   # INSERT Price History                                ‚îÇ
‚îÇ   await db.execute(insert(PriceHistory).values(         ‚îÇ
‚îÇ     product_id=product_id,                              ‚îÇ
‚îÇ     old_price=329.99,  # from DB                        ‚îÇ
‚îÇ     new_price=348.99,  # just scraped                   ‚îÇ
‚îÇ     recorded_at=datetime.utcnow()                       ‚îÇ
‚îÇ   ))                                                      ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ   # COMMIT automatically at end of context              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 8: Acknowledge Job & Update Status                  ‚îÇ
‚îÇ # Mark as processed in Redis                             ‚îÇ
‚îÇ await redis.xack("scraper:amazon", "scrapers", msg_id)  ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ # Update job status in DB                               ‚îÇ
‚îÇ await db.execute(                                        ‚îÇ
‚îÇ   update(Job).where(Job.id == 789).values(              ‚îÇ
‚îÇ     status="SUCCESS",                                    ‚îÇ
‚îÇ     result={"product_id": 12345},                       ‚îÇ
‚îÇ     completed_at=datetime.utcnow()                      ‚îÇ
‚îÇ   )                                                       ‚îÇ
‚îÇ )                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 9: Publish Event (Pub/Sub)                         ‚îÇ
‚îÇ await redis.publish(                                     ‚îÇ
‚îÇ   "product.changed",                                     ‚îÇ
‚îÇ   json.dumps({                                           ‚îÇ
‚îÇ     "type": "product.updated",                          ‚îÇ
‚îÇ     "product_id": 12345,                                ‚îÇ
‚îÇ     "change": {"price": 329.99 ‚Üí 348.99},              ‚îÇ
‚îÇ     "timestamp": datetime.utcnow()                      ‚îÇ
‚îÇ   })                                                     ‚îÇ
‚îÇ )                                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ                   ‚îÇ
      ‚ñº                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ policy_engine  ‚îÇ  ‚îÇ notifications    ‚îÇ
‚îÇ listens to     ‚îÇ  ‚îÇ service listens  ‚îÇ
‚îÇ event & runs:  ‚îÇ  ‚îÇ to event &       ‚îÇ
‚îÇ                ‚îÇ  ‚îÇ sends alert to   ‚îÇ
‚îÇ IF price down  ‚îÇ  ‚îÇ user if price    ‚îÇ
‚îÇ by 5%+ THEN    ‚îÇ  ‚îÇ dropped >5%      ‚îÇ
‚îÇ - Queue check  ‚îÇ  ‚îÇ                  ‚îÇ
‚îÇ - Stock low?   ‚îÇ  ‚îÇ "Price dropped!" ‚îÇ
‚îÇ - Margin OK?   ‚îÇ  ‚îÇ                  ‚îÇ
‚îÇ - Auto pause?  ‚îÇ  ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ Both update DB & publish new   ‚îÇ
      ‚îÇ events if policies trigger     ‚îÇ
      ‚ñº
    ‚úÖ COMPLETE!
    
Total time: ~5-10 seconds from user request to completion!
User can check status: GET /jobs/789 ‚Üí {"status": "SUCCESS"}
```

---

## üìä DATABASE SCHEMA (15 Tables)

### Complete Table Definitions

```python
# TABLE 1: users
users:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ email (UNIQUE)
  ‚îú‚îÄ password_hash (bcrypt)
  ‚îú‚îÄ first_name
  ‚îú‚îÄ last_name
  ‚îú‚îÄ tier (free, pro, enterprise)
  ‚îú‚îÄ api_key (for integrations)
  ‚îú‚îÄ created_at
  ‚îú‚îÄ updated_at
  ‚îî‚îÄ is_active (soft delete)

# TABLE 2: sessions
sessions:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ token (JWT)
  ‚îú‚îÄ refresh_token
  ‚îú‚îÄ expires_at
  ‚îú‚îÄ created_at
  ‚îî‚îÄ revoked_at (soft delete)

# TABLE 3: products
products:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ supplier_id (FK)
  ‚îú‚îÄ asin (or item_id, sku)
  ‚îú‚îÄ title
  ‚îú‚îÄ description
  ‚îú‚îÄ price (decimal)
  ‚îú‚îÄ stock (integer, can be "In Stock" text)
  ‚îú‚îÄ rating (decimal 0-5)
  ‚îú‚îÄ reviews_count
  ‚îú‚îÄ images (JSONB array of URLs)
  ‚îú‚îÄ url
  ‚îú‚îÄ last_scraped_at
  ‚îú‚îÄ created_at
  ‚îú‚îÄ updated_at
  ‚îî‚îÄ is_archived

# TABLE 4: price_history
price_history:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ product_id (FK)
  ‚îú‚îÄ old_price (decimal)
  ‚îú‚îÄ new_price (decimal)
  ‚îú‚îÄ price_change_percent (decimal)
  ‚îú‚îÄ recorded_at
  ‚îî‚îÄ reason (manual, scrape, api)

# TABLE 5: stock_history
stock_history:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ product_id (FK)
  ‚îú‚îÄ old_stock (integer)
  ‚îú‚îÄ new_stock (integer)
  ‚îú‚îÄ recorded_at
  ‚îî‚îÄ reason (scrape, api, manual)

# TABLE 6: suppliers
suppliers:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ name (amazon, aliexpress, costco)
  ‚îú‚îÄ base_url
  ‚îú‚îÄ rate_limit (requests per minute)
  ‚îú‚îÄ requires_js (bool, needs browser)
  ‚îú‚îÄ scraper_config (JSONB, selectors, etc)
  ‚îú‚îÄ is_active
  ‚îî‚îÄ created_at

# TABLE 7: store_accounts
store_accounts:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ marketplace (ebay, shopify, etsy)
  ‚îú‚îÄ account_name
  ‚îú‚îÄ api_key (encrypted)
  ‚îú‚îÄ api_secret (encrypted)
  ‚îú‚îÄ oauth_token (encrypted)
  ‚îú‚îÄ oauth_refresh_token (encrypted)
  ‚îú‚îÄ oauth_expires_at
  ‚îú‚îÄ is_connected
  ‚îú‚îÄ last_synced_at
  ‚îú‚îÄ created_at
  ‚îî‚îÄ updated_at

# TABLE 8: listings
listings:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ product_id (FK)
  ‚îú‚îÄ store_account_id (FK)
  ‚îú‚îÄ external_listing_id (eBay item ID, Shopify product ID)
  ‚îú‚îÄ title (can override product title)
  ‚îú‚îÄ description
  ‚îú‚îÄ price (current listing price)
  ‚îú‚îÄ quantity_available
  ‚îú‚îÄ status (Pending, Active, Paused, Ended, Delisted)
  ‚îú‚îÄ status_reason (low_margin, manual_pause, out_of_stock)
  ‚îú‚îÄ created_at
  ‚îú‚îÄ updated_at
  ‚îî‚îÄ ended_at

# TABLE 9: marketplace_data
marketplace_data:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ listing_id (FK)
  ‚îú‚îÄ date (DATE, one record per day)
  ‚îú‚îÄ views (integer)
  ‚îú‚îÄ clicks (integer)
  ‚îú‚îÄ sales (integer)
  ‚îú‚îÄ revenue (decimal)
  ‚îú‚îÄ cost_of_goods_sold (decimal)
  ‚îú‚îÄ profit (calculated or stored)
  ‚îú‚îÄ avg_rating_received (decimal)
  ‚îú‚îÄ customer_feedbacks (integer)
  ‚îî‚îÄ notes

# TABLE 10: alerts
alerts:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ type (low_stock, low_margin, price_drop, policy_trigger)
  ‚îú‚îÄ product_id (FK, nullable)
  ‚îú‚îÄ listing_id (FK, nullable)
  ‚îú‚îÄ severity (info, warning, critical)
  ‚îú‚îÄ message
  ‚îú‚îÄ data (JSONB, context data)
  ‚îú‚îÄ is_read
  ‚îú‚îÄ read_at
  ‚îú‚îÄ created_at
  ‚îî‚îÄ acknowledged_at

# TABLE 11: jobs
jobs:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ type (scrape_amazon, track_products, sync_ebay, upload_shopify)
  ‚îú‚îÄ status (PENDING, RUNNING, SUCCESS, FAILED, CANCELLED)
  ‚îú‚îÄ params (JSONB, input data {asin, product_id, etc})
  ‚îú‚îÄ result (JSONB, output {product_id, error, etc})
  ‚îú‚îÄ error_message
  ‚îú‚îÄ retry_count (0-3)
  ‚îú‚îÄ created_at
  ‚îú‚îÄ started_at
  ‚îú‚îÄ completed_at
  ‚îî‚îÄ next_retry_at

# TABLE 12: proxy_pool
proxy_pool:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ host (IP address)
  ‚îú‚îÄ port (integer)
  ‚îú‚îÄ username (nullable)
  ‚îú‚îÄ password (nullable, encrypted)
  ‚îú‚îÄ protocol (http, socks5)
  ‚îú‚îÄ country
  ‚îú‚îÄ health_score (0-100, updated by proxy_scorer)
  ‚îú‚îÄ success_count (successful requests)
  ‚îú‚îÄ failure_count (failed requests)
  ‚îú‚îÄ last_checked_at
  ‚îú‚îÄ last_failed_at
  ‚îú‚îÄ is_active
  ‚îî‚îÄ created_at

# TABLE 13: analytics_cache
analytics_cache:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ metric_type (total_revenue, total_profit, top_products, etc)
  ‚îú‚îÄ time_period (daily, weekly, monthly)
  ‚îú‚îÄ data (JSONB, complex calculated data)
  ‚îú‚îÄ computed_at
  ‚îú‚îÄ expires_at (for TTL)
  ‚îî‚îÄ created_at

# TABLE 14: audit_log
audit_log:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ action (created, updated, deleted, paused, resumed)
  ‚îú‚îÄ resource_type (product, listing, store_account)
  ‚îú‚îÄ resource_id
  ‚îú‚îÄ old_value (JSONB, what changed)
  ‚îú‚îÄ new_value (JSONB, to what)
  ‚îú‚îÄ ip_address
  ‚îú‚îÄ user_agent
  ‚îú‚îÄ timestamp
  ‚îî‚îÄ notes

# TABLE 15: notifications
notifications:
  ‚îú‚îÄ id (PK)
  ‚îú‚îÄ user_id (FK)
  ‚îú‚îÄ type (alert, policy_trigger, job_complete, report)
  ‚îú‚îÄ recipient (email, sms, webhook)
  ‚îú‚îÄ subject
  ‚îú‚îÄ body (JSONB or text)
  ‚îú‚îÄ is_sent
  ‚îú‚îÄ sent_at
  ‚îú‚îÄ created_at
  ‚îî‚îÄ metadata (JSONB)
```

---

## üîå PLUGIN SYSTEMS

### Scraper Plugin Pattern

```python
# STEP 1: Define Base Class (scrapers/base.py)
class BaseScraper:
    async def get_product(self, id: str) -> Product:
        """Get single product"""
        raise NotImplementedError
    
    async def search(self, query: str) -> List[Product]:
        """Search products"""
        raise NotImplementedError

# STEP 2: Implement for Amazon (scrapers/amazon.py)
class AmazonScraper(BaseScraper):
    async def get_product(self, asin: str) -> Product:
        # Use curl-cffi with Chrome impersonation
        # Rotate proxies from proxy_pool
        # Handle rate limiting
        # Parse HTML with CSS selectors
        return Product(...)

# STEP 3: Register (scrapers/registry.py)
scrapers = {
    "amazon": AmazonScraper(),
    "aliexpress": AliExpressScraper(),
}

def get_scraper(name: str) -> BaseScraper:
    if name not in scrapers:
        raise ValueError(f"Unknown scraper: {name}")
    return scrapers[name]

# STEP 4: Use in Worker
scraper = get_scraper("amazon")
product = await scraper.get_product(asin)

# TO ADD NEW SCRAPER (e.g., Costco):
# 1. Create scrapers/costco.py
# 2. Class CostcoScraper(BaseScraper)
# 3. Implement get_product() and search()
# 4. Add to registry: scrapers["costco"] = CostcoScraper()
# ‚úÖ NO changes to core code!
```

### Marketplace Plugin Pattern

```python
# STEP 1: Define Base Class (marketplaces/base.py)
class MarketplaceClient:
    async def create_listing(self, product: Product, price: float) -> str:
        """Create listing, return listing_id"""
        raise NotImplementedError
    
    async def update_price(self, listing_id: str, price: float) -> bool:
        """Update price"""
        raise NotImplementedError
    
    async def withdraw(self, listing_id: str) -> bool:
        """Remove listing"""
        raise NotImplementedError

# STEP 2: Implement for eBay (marketplaces/ebay.py)
class EBayClient(MarketplaceClient):
    async def create_listing(self, product, price) -> str:
        # Load OAuth2 token from store_account
        # Make API call to eBay Inventory API
        # createOffer() ‚Üí publishOffer()
        # Return offerId
        return offering_id
    
    async def update_price(self, listing_id, price) -> bool:
        # Make API call to update price
        # Handle rate limiting (250/day)
        return True

# STEP 3: Register (marketplaces/registry.py)
marketplaces = {
    "ebay": EBayClient(),
    "shopify": ShopifyClient(),
}

def get_marketplace(name: str) -> MarketplaceClient:
    return marketplaces[name]

# STEP 4: Use in Worker
client = get_marketplace("ebay")
listing_id = await client.create_listing(product, price)

# TO ADD NEW MARKETPLACE (e.g., Shopify):
# 1. Create marketplaces/shopify.py
# 2. Class ShopifyClient(MarketplaceClient)
# 3. Implement create_listing(), update_price(), etc
# 4. Add to registry: marketplaces["shopify"] = ShopifyClient()
# ‚úÖ NO changes to core code!
```

---

## üîß TECHNOLOGY STACK SPECIFICATIONS

### Python Ecosystem (3.11+)

```
Web Framework:
- FastAPI 0.109+ (async-first, auto-validation, Swagger)
- Uvicorn (ASGI server, 10+ workers)

Database:
- SQLAlchemy 2.0 (async ORM, type-safe)
- asyncpg 0.28+ (PostgreSQL async driver)
- PostgreSQL 15+ (production database)

Caching & Queues:
- redis.asyncio 5.0+ (async Redis client)
- Redis 7+ (Streams, Pub/Sub, Cache)

Data Validation:
- Pydantic v2 (request/response validation)
- Pydantic-settings (config management)

Authentication & Security:
- python-jose (JWT tokens)
- bcrypt (password hashing, 10+ rounds)
- passlib (password utilities)

Web Scraping & HTTP:
- curl-cffi 0.6+ (TLS fingerprint spoofing, Chrome impersonation)
- aiohttp (async HTTP client)

Testing:
- pytest (testing framework)
- pytest-asyncio (async test support)
- pytest-cov (coverage reporting)
- factoryboy (test fixtures)
- fakeredis (mock Redis for testing)

Development Tools:
- Black (code formatting)
- Flake8 (linting)
- mypy (type checking)
- pre-commit (git hooks)

Monitoring & Logging:
- structlog (structured JSON logging)
- prometheus-client (metrics)
- python-json-logger (JSON log format)

Deployment:
- Docker (containerization)
- Docker Compose (local development)
- Kubernetes (production orchestration)
- Gunicorn (WSGI server, production)
```

---

## üìã COMPLETE BUILD ROADMAP (14 STEPS)

```
PHASE 1: CORE FOUNDATION (Days 1-2)
‚îú‚îÄ STEP 1: config.py (Pydantic BaseSettings) ‚úÖ
‚îú‚îÄ STEP 2: main.py (FastAPI app, minimal) ‚úÖ
‚îú‚îÄ STEP 3A: core/database.py ‚úÖ (SQLAlchemy async)
‚îú‚îÄ STEP 3B: core/redis.py (Redis async)
‚îú‚îÄ STEP 4A: core/security.py (JWT, bcrypt)
‚îú‚îÄ STEP 4B: core/exceptions.py (Custom errors)
‚îî‚îÄ STEP 4C: core/logging.py (Structured logging)

PHASE 2: DATA MODELS (Day 3)
‚îú‚îÄ STEP 5A: models/base.py (Base ORM model)
‚îú‚îÄ STEP 5B: models/user.py (User + Session models)
‚îú‚îÄ STEP 5C: models/product.py (Product + History models)
‚îú‚îÄ STEP 5D: models/listing.py (Listing + Marketplace models)
‚îî‚îÄ STEP 5E: models/admin.py (Jobs, Alerts, etc)

PHASE 3: VALIDATION (Day 3)
‚îú‚îÄ STEP 6A: schemas/user.py
‚îú‚îÄ STEP 6B: schemas/product.py
‚îú‚îÄ STEP 6C: schemas/listing.py
‚îî‚îÄ STEP 6D: schemas/common.py

PHASE 4: API ROUTES (Day 4)
‚îú‚îÄ STEP 7A: api/v1/router.py (API router setup)
‚îú‚îÄ STEP 7B: api/v1/endpoints/auth.py (Login, signup, refresh)
‚îú‚îÄ STEP 7C: api/v1/endpoints/products.py (CRUD + import)
‚îú‚îÄ STEP 7D: api/v1/endpoints/listings.py (CRUD + upload)
‚îú‚îÄ STEP 7E: api/v1/endpoints/stores.py (OAuth connect/disconnect)
‚îî‚îÄ STEP 7F: api/v1/endpoints/analytics.py (Dashboard, trends)

PHASE 5: BUSINESS LOGIC (Day 5)
‚îú‚îÄ STEP 8A: services/tracker_service.py (Parallel tracking)
‚îú‚îÄ STEP 8B: services/policy_engine.py (Business rules)
‚îú‚îÄ STEP 8C: services/analytics_service.py (Metrics calculation)
‚îî‚îÄ STEP 8D: services/state_machine.py (Listing states)

PHASE 6: PLUGINS (Days 6-7)
‚îú‚îÄ STEP 9A: scrapers/base.py (Abstract base)
‚îú‚îÄ STEP 9B: scrapers/amazon.py (Amazon implementation)
‚îú‚îÄ STEP 9C: scrapers/registry.py (Plugin discovery)
‚îú‚îÄ STEP 9D: scrapers/anti_detect.py (TLS helpers)
‚îú‚îÄ STEP 10A: marketplaces/base.py (Abstract base)
‚îú‚îÄ STEP 10B: marketplaces/ebay.py (eBay implementation)
‚îî‚îÄ STEP 10C: marketplaces/registry.py (Plugin discovery)

PHASE 7: WORKERS (Day 8)
‚îú‚îÄ STEP 11A: workers/scraper_worker.py (Job processing)
‚îú‚îÄ STEP 11B: workers/tracker_worker.py (Change detection)
‚îî‚îÄ STEP 11C: workers/syncer_worker.py (Upload to marketplace)

PHASE 8: INFRASTRUCTURE (Days 9-10)
‚îú‚îÄ STEP 12: tests/ (Unit, integration, E2E, fixtures)
‚îú‚îÄ STEP 13: Dockerfile (Multi-stage container)
‚îú‚îÄ STEP 14: docker-compose.yml (Local development)
‚îî‚îÄ STEP 15: Deployment configs (Kubernetes, CI/CD)
```

---

## ‚ö†Ô∏è STRICT CODE QUALITY RULES

### EVERY FILE MUST HAVE:

```python
# 1. Type Hints (MANDATORY)
async def get_products(
    user_id: int,
    limit: int = 10,
    offset: int = 0
) -> List[ProductSchema]:
    """Get products for user with pagination."""
    # NOT: async def get_products(user_id, limit=10):

# 2. Docstrings (MANDATORY)
async def track_product(product_id: int) -> bool:
    """
    Track product price and stock changes.
    
    Args:
        product_id: Product ID to track
    
    Returns:
        bool: True if changes detected, False otherwise
    
    Raises:
        ProductNotFound: If product doesn't exist
    """

# 3. Error Handling (MANDATORY)
try:
    result = await scraper.get_product(asin)
except Exception as e:
    logger.error("Scrape failed", asin=asin, error=str(e))
    # NOT: except: pass

# 4. Async/Await (NO SYNC CODE ALLOWED)
# ‚úÖ GOOD:
product = await db.execute(select(Product).where(...))

# ‚ùå BAD:
product = db.query(Product).filter(...).first()

# 5. Logging (MANDATORY)
logger.info("product_imported", product_id=123, asin="B123", user_id=456)
# NOT: print("Product imported")

# 6. Pydantic Validation (MANDATORY)
class ProductSchema(BaseModel):
    model_config = ConfigDict(from_attributes=True)
    id: int
    asin: str
    price: Decimal
    title: str

# 7. SQLAlchemy selectinload (NO N+1 QUERIES)
stmt = select(Product).options(
    selectinload(Product.listings),
    selectinload(Product.price_history)
)
# NOT: for product in products: product.listings (triggers N queries)

# 8. Transaction Management (DATA INTEGRITY)
async with db.begin():
    await db.execute(insert(Product).values(...))
    await db.execute(insert(PriceHistory).values(...))
    # Auto-commits on success, rolls back on error

# 9. No Hardcoded Values (ALWAYS USE CONFIG)
# ‚úÖ GOOD:
api_key = settings.EBAY_API_KEY

# ‚ùå BAD:
api_key = "sk-12345"

# 10. Comments for Complex Logic (ONLY)
# ‚úÖ GOOD - complex logic gets comment:
# Calculate price with 20% margin and 2.9% + $0.30 fee
price_with_margin = (cost / 0.8) + (cost / 0.8 * 0.029) + 0.30

# ‚ùå BAD - obvious code gets comment:
# Increment counter by 1
counter += 1
```

---
